# Классификация текстов 

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

Постройте модель со значением метрики качества *F1* не меньше 0.75. 

**Инструкция по выполнению проекта**

1. Загрузка и подготовьте данные.
2. Обучение разных модели. 
3. Выводы.

Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.

**Описание данных**

Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.

# Основной вывод
В ходе работы были обучены две модели с подбором гиперпараметров и кросс-валидацией: логистическая регрессия и случайный лес.

Логистическая регрессия обучалась в 4 раза дольше, чем случайный лес (20 минут против 4), но зато выдала удовлетворительный результат f1 меры больше 0.75, в отличие от случайного леса.

На тестовой же выборке наилучшая модель логистической регрессии показала значение f1-меры в 0.77.    

Для обучения на эмбдеддингах для предобученной модели BERT на такой маленькой выборке в 800 строк результат оказался лучше, чем для tf-idf: f1-score равняется 0.91. Однако и время обучения оказалось наибольшим из методов (порядка 40 минут), хотя в целом сопоставимым с суммарным временем лемматизации (примерно 15 минут) и обучением линейной регрессии (20 минут)
